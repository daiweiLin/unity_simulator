{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# source:\n",
    "# https://github.com/theRealSuperMario/supermariopy/blob/master/scripts/tflogs2pandas.py\n",
    "#########################################\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import click\n",
    "import pprint\n",
    "\n",
    "\n",
    "# Extraction function\n",
    "def tflog2pandas(path: str) -> pd.DataFrame:\n",
    "    \"\"\"convert single tensorflow log file to pandas DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to tensorflow log file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        converted dataframe\n",
    "    \"\"\"\n",
    "    DEFAULT_SIZE_GUIDANCE = {\n",
    "        \"compressedHistograms\": 1,\n",
    "        \"images\": 1,\n",
    "        \"scalars\": 0,  # 0 means load all\n",
    "        \"histograms\": 1,\n",
    "    }\n",
    "    runlog_data = pd.DataFrame()\n",
    "    try:\n",
    "        event_acc = EventAccumulator(path, DEFAULT_SIZE_GUIDANCE)\n",
    "        event_acc.Reload()\n",
    "        tags = event_acc.Tags()[\"scalars\"]\n",
    "        for tag in tags:\n",
    "            if tag == \"rollout/return\" or tag == \"rollout/Q_mean\": #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Made change here\n",
    "                event_list = event_acc.Scalars(tag)\n",
    "                values = list(map(lambda x: x.value, event_list))\n",
    "                step = list(map(lambda x: x.step, event_list))\n",
    "                r = pd.Series(data=values, index=step, name=tag)\n",
    "                runlog_data = pd.concat([runlog_data, r], axis=1)\n",
    "    # Dirty catch of DataLossError\n",
    "    except:\n",
    "        print(\"Event file possibly corrupt: {}\".format(path))\n",
    "        traceback.print_exc()\n",
    "    return runlog_data\n",
    "\n",
    "\n",
    "def many_logs2pandas(event_paths):\n",
    "    all_logs = pd.DataFrame()\n",
    "    for path in event_paths:\n",
    "        log = tflog2pandas(path)\n",
    "        if log is not None:\n",
    "            if all_logs.shape[0] == 0:\n",
    "                all_logs = log\n",
    "            else:\n",
    "                all_logs = all_logs.append(log, ignore_index=True)\n",
    "    return all_logs\n",
    "\n",
    "\n",
    "def extract_tf_to_csv(logfile: str, write_pkl: bool, write_csv: bool, out_dir: str):\n",
    "    \"\"\"This is a enhanced version of https://gist.github.com/ptschandl/ef67bbaa93ec67aba2cab0a7af47700b\n",
    "    This script exctracts variables from all logs from tensorflow event files (\"event*\"),\n",
    "    writes them to Pandas and finally stores them a csv-file or pickle-file including all (readable) runs of the logging directory.\n",
    "    Example usage:\n",
    "    # create csv file from all tensorflow logs in provided directory (.) and write it to folder \"./converted\"\n",
    "    tflogs2pandas.py . --csv --no-pkl --o converted\n",
    "    # creaste csv file from tensorflow logfile only and write into and write it to folder \"./converted\"\n",
    "    tflogs2pandas.py tflog.hostname.12345 --csv --no-pkl --o converted\n",
    "    \"\"\"\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    if os.path.isfile(logfile):\n",
    "        event_paths = [logfile]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"input argument {} has to be a file\".format(\n",
    "                logfile\n",
    "            )\n",
    "        )\n",
    "    # Call & append\n",
    "    if event_paths:\n",
    "        pp.pprint(\"Found tensorflow logs to process:\")\n",
    "        pp.pprint(event_paths)\n",
    "        all_logs = many_logs2pandas(event_paths)\n",
    "        pp.pprint(\"Head of created dataframe\")\n",
    "        pp.pprint(all_logs.head())\n",
    "\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        run_id = logfile.split(\".\")[5]+logfile.split(\".\")[6]\n",
    "        mode = logfile.split(\"/\")[-1].split(\"\\\\\")[1]\n",
    "        if write_csv:\n",
    "            print(\"saving to csv file\")\n",
    "            out_file = os.path.join(out_dir, \"run_\"+mode+\"_\"+run_id+\"_file.csv\")\n",
    "            print(out_file)\n",
    "            all_logs.to_csv(out_file, index=None)\n",
    "        if write_pkl:\n",
    "            print(\"saving to pickle file\")\n",
    "            out_file = os.path.join(out_dir, \"all_training_logs_in_one_file.pkl\")\n",
    "            print(out_file)\n",
    "            all_logs.to_pickle(out_file)\n",
    "    else:\n",
    "        print(\"No event paths have been found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddpg: 3 files:\n",
      "../SHARCNET/Results/multi/aug_obs/ddpg\\PLA\\2019-10-18-150124-0-20\\summary\\tb\\events.out.tfevents.1571425307.gra1078\n",
      "../SHARCNET/Results/multi/aug_obs/ddpg\\PLA\\2019-10-18-150130-1-20\\summary\\tb\\events.out.tfevents.1571425314.gra583\n",
      "../SHARCNET/Results/multi/aug_obs/ddpg\\SARA\\2019-10-18-150125-1-20\\summary\\tb\\events.out.tfevents.1571425308.gra586\n"
     ]
    }
   ],
   "source": [
    "# folders = [\"point125\",\"point25\",\"point5\",\"point75\", \"one\"]\n",
    "# folders = [\"vpoint1\",\"vpoint3\"]\n",
    "folders = [\"ddpg\"]\n",
    "event_files = dict()\n",
    "for folder in folders:\n",
    "    \n",
    "    event_files[folder] = glob.glob(\"../SHARCNET/Results/multi/aug_obs/\"+folder+\"/**/events*\", recursive=True)\n",
    "    event_files[folder].sort()\n",
    "    print(folder+\": {} files:\".format(len(event_files[folder])))\n",
    "    for f in event_files[folder]:\n",
    "            print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Found tensorflow logs to process:'\n",
      "[   '../SHARCNET/Results/multi/aug_obs/ddpg\\\\PLA\\\\2019-10-18-150124-0-20\\\\summary\\\\tb\\\\events.out.tfevents.1571425307.gra1078']\n",
      "'Head of created dataframe'\n",
      "   rollout/Q_mean  rollout/return\n",
      "1        0.006485       29.032724\n",
      "2        0.076601       40.290215\n",
      "3        0.151560       37.350185\n",
      "4        0.226473       46.165829\n",
      "5        0.299477       36.884808\n",
      "saving to csv file\n",
      "../SHARCNET/Results/Tensorboard_to_CSV/multi/aug_obs/ddpg\\run_PLA_1571425307gra1078_file.csv\n",
      "'Found tensorflow logs to process:'\n",
      "[   '../SHARCNET/Results/multi/aug_obs/ddpg\\\\PLA\\\\2019-10-18-150130-1-20\\\\summary\\\\tb\\\\events.out.tfevents.1571425314.gra583']\n",
      "'Head of created dataframe'\n",
      "   rollout/Q_mean  rollout/return\n",
      "1       -0.001484       23.738237\n",
      "2        0.070129       42.908173\n",
      "3        0.143207       39.013187\n",
      "4        0.219195       41.568024\n",
      "5        0.294274       36.356750\n",
      "saving to csv file\n",
      "../SHARCNET/Results/Tensorboard_to_CSV/multi/aug_obs/ddpg\\run_PLA_1571425314gra583_file.csv\n",
      "'Found tensorflow logs to process:'\n",
      "[   '../SHARCNET/Results/multi/aug_obs/ddpg\\\\SARA\\\\2019-10-18-150125-1-20\\\\summary\\\\tb\\\\events.out.tfevents.1571425308.gra586']\n",
      "'Head of created dataframe'\n",
      "   rollout/Q_mean  rollout/return\n",
      "1        0.005089       17.884930\n",
      "2        0.071884       22.159029\n",
      "3        0.140546       20.334116\n",
      "4        0.203495       37.486446\n",
      "5        0.269245       38.649391\n",
      "saving to csv file\n",
      "../SHARCNET/Results/Tensorboard_to_CSV/multi/aug_obs/ddpg\\run_SARA_1571425308gra586_file.csv\n"
     ]
    }
   ],
   "source": [
    "out_root_dir = \"../SHARCNET/Results/Tensorboard_to_CSV/multi/aug_obs/\"\n",
    "for folder, files in event_files.items():\n",
    "    out_dir = out_root_dir+folder\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    for f in files:\n",
    "        extract_tf_to_csv(logfile=f, write_pkl=False, write_csv=True, out_dir=out_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
